{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82730b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd1710e",
   "metadata": {},
   "source": [
    "#### 載入套件與資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875c9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import optuna\n",
    "\n",
    "# 載入資料\n",
    "df_train_full = pd.read_csv(\"AMAZON_FREIGHT_train.csv\")\n",
    "df_test_final = pd.read_csv(\"AMAZON_FREIGHT_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2655aabb",
   "metadata": {},
   "source": [
    "#### 自訂 Target Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9872e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.mapping_ = {}\n",
    "        self.defaults_ = {}\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # 計算每個類別的平均 target（log_cost）\n",
    "        X = pd.DataFrame(X)\n",
    "        self.columns = X.columns.tolist()\n",
    "        for col in self.columns:\n",
    "            df = pd.DataFrame({col: X[col], 'target': y})\n",
    "            self.mapping_[col] = df.groupby(col)['target'].mean().to_dict()\n",
    "            self.defaults_[col] = df['target'].mean()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # 將欄位值轉換為對應的平均 target 值\n",
    "        X = pd.DataFrame(X)\n",
    "        return np.hstack([\n",
    "            X[col].map(self.mapping_[col]).fillna(self.defaults_[col]).values.reshape(-1, 1)\n",
    "            for col in self.columns\n",
    "        ])\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return [f\"{col}_target_encoded\" for col in self.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e103f770",
   "metadata": {},
   "source": [
    "#### 自訂 Frequency Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b409c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    將分類特徵編碼為相對頻率 (0~1)。\n",
    "    可同時處理多欄位，支援 get_feature_names_out。\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.freq_maps_ = {}\n",
    "        self.columns_ = []\n",
    "        self.global_freq_ = {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        X = pd.DataFrame(X)\n",
    "        self.columns_ = X.columns.tolist()\n",
    "        n_samples = len(X)\n",
    "        for col in self.columns_:\n",
    "            freq = X[col].value_counts(dropna=False) / n_samples\n",
    "            self.freq_maps_[col] = freq.to_dict()\n",
    "            self.global_freq_[col] = 1.0 / n_samples      # fallback ≈最小頻率\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        encoded = []\n",
    "        for col in self.columns_:\n",
    "            encoded_col = X[col].map(self.freq_maps_[col]).fillna(self.global_freq_[col])\n",
    "            encoded.append(encoded_col.values.reshape(-1, 1))\n",
    "        return np.hstack(encoded)\n",
    "    \n",
    "    # 讓 ColumnTransformer 能自動抓欄位名\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return [f\"{col}_freq_encoded\" for col in self.columns_]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c24bf",
   "metadata": {},
   "source": [
    "#### 把欄位清單和 ColumnTransformer 都包成一支小函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5935ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. 產生 feature_cols：只告訴你有哪些欄位\n",
    "# -----------------------------------------------------------\n",
    "def build_feature_cols(\n",
    "        numeric_cols,\n",
    "        target_encode_cols=None,\n",
    "        freq_encode_cols=None\n",
    "    ):\n",
    "    \"\"\"回傳最終要用來建模的欄位清單（list）。\"\"\"\n",
    "    feature_cols = list(numeric_cols)\n",
    "    if target_encode_cols:\n",
    "        feature_cols += target_encode_cols\n",
    "    if freq_encode_cols:\n",
    "        feature_cols += freq_encode_cols\n",
    "    return feature_cols\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. 產生 preprocessor：給 Pipeline 用的 ColumnTransformer\n",
    "# -----------------------------------------------------------\n",
    "def build_preprocessor(\n",
    "        numeric_cols,\n",
    "        target_encode_cols=None,\n",
    "        freq_encode_cols=None\n",
    "    ):\n",
    "    \"\"\"回傳 ColumnTransformer（直接丟進 Pipeline）。\"\"\"\n",
    "    transformers = []\n",
    "    if target_encode_cols:\n",
    "        transformers.append(('te', TargetEncoder(), target_encode_cols))\n",
    "    if freq_encode_cols:\n",
    "        transformers.append(('freq', FrequencyEncoder(), freq_encode_cols))\n",
    "\n",
    "    # numeric_cols 沒有指定 transformer ⇒ remainder='passthrough' 直接帶出\n",
    "    return ColumnTransformer(\n",
    "        transformers=transformers,\n",
    "        remainder='passthrough'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837025c9",
   "metadata": {},
   "source": [
    "#### 指定特徵欄位並進行encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b591d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測目標\n",
    "target_col = 'log_cost'\n",
    "\n",
    "# 類別與數值欄位\n",
    "numeric_cols       = [\"log_weight\",\"log_Hdis\",]\n",
    "target_encode_cols = [\"to_state\"]   # 不用就改成 []\n",
    "freq_encode_cols   = []   # 不用就改成 []                         \n",
    "\n",
    "# 1. 取得欄位清單（做 EDA、選擇 X 時會用到）\n",
    "feature_cols = build_feature_cols(\n",
    "    numeric_cols,\n",
    "    target_encode_cols,\n",
    "    freq_encode_cols\n",
    ")\n",
    "\n",
    "# 2. 取得 ColumnTransformer（接 Pipeline）\n",
    "preprocessor = build_preprocessor(\n",
    "    numeric_cols,\n",
    "    target_encode_cols,\n",
    "    freq_encode_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e968cf85",
   "metadata": {},
   "source": [
    "#### 劃分樣本大小間距"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19927cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_budget(train_n, param_dim=3):\n",
    "    \"\"\"\n",
    "    三檔分級：\n",
    "        小樣本  (<  500) → n_trials = 120, timeout =  600s\n",
    "        中樣本  (≤ 3000) → n_trials = 80 , timeout = 1200s\n",
    "        大樣本  (> 3000) → n_trials = 60 , timeout = 1800s\n",
    "    \"\"\"\n",
    "    # ── 固定試驗數（可依需求微調） ──\n",
    "    if train_n < 500:          # 小\n",
    "        n_trials = 120\n",
    "        timeout  = 600\n",
    "    elif train_n <= 3000:      # 中\n",
    "        n_trials = 80\n",
    "        timeout  = 1200\n",
    "    else:                      # 大\n",
    "        n_trials = 60\n",
    "        timeout  = 1800\n",
    "        \n",
    "    # 最少仍保底「參數維度 × 4」以避免過低\n",
    "    n_trials = max(n_trials, 4 * param_dim)\n",
    "    return n_trials, timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1c199e",
   "metadata": {},
   "source": [
    "#### 建立模型並輸出指標結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 若想用 KFold -> from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "results = []\n",
    "\n",
    "for method in df_train_full['ship_method'].unique():\n",
    "    # 篩選該運送方式資料\n",
    "    df_method = df_train_full[df_train_full['ship_method'] == method].copy()\n",
    "    \n",
    "    # 根據資料量決定 n_trials\n",
    "    train_n = len(df_method)   # 只看 train+val 前的筆數即可\n",
    "    n_trials, time_budget = choose_budget(train_n)\n",
    "\n",
    "    X = df_method[feature_cols]\n",
    "    y = df_method[target_col]\n",
    "\n",
    "    # 拆分訓練與驗證集\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 定義 Optuna 目標函數\n",
    "    def objective(trial):\n",
    "         # --- 建立「新的」preprocessor ---\n",
    "        preprocessor = build_preprocessor(\n",
    "        numeric_cols,\n",
    "        target_encode_cols,\n",
    "        freq_encode_cols\n",
    "    )\n",
    "        \n",
    "        # 超參數範圍\n",
    "        C       = trial.suggest_loguniform('C',       1e-3, 1e3)\n",
    "        epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1.0)\n",
    "        gamma   = trial.suggest_loguniform('gamma',   1e-4, 10)\n",
    "\n",
    "        # 建立 SVR 模型\n",
    "        svr = SVR(kernel='rbf', C=C, epsilon=epsilon, gamma=gamma)\n",
    "\n",
    "        # 建立 pipeline\n",
    "        svr_model = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),                 # 僅做編碼\n",
    "            ('scaler_post',  StandardScaler(with_mean=False)),  # 統一尺度\n",
    "            ('regressor',    svr)\n",
    "        ])\n",
    "\n",
    "        # 模型訓練\n",
    "        svr_model.fit(X_train, y_train)\n",
    "\n",
    "        # -------- 若想用 K-Fold，把下三行改成 cross_val_score --------\n",
    "        # 使用 KFold 交叉驗證\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        scores = cross_val_score(svr_model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "        return -scores.mean()  # cross_val_score 回傳負的 MSE，取負號變回正的 MSE\n",
    "        # -----------------------------------------------------------\n",
    "    \n",
    "    # 使用 Optuna 優化超參數\n",
    "    study = optuna.create_study(direction='minimize',\n",
    "                                pruner=optuna.pruners.HyperbandPruner())\n",
    "    study.optimize(objective, n_trials=n_trials, timeout=time_budget,show_progress_bar=True)\n",
    "    \n",
    "    # 儲存最佳參數\n",
    "    best_params = study.best_params\n",
    "    print(f\"[{method}] best params:\", best_params)\n",
    "\n",
    "    # 使用最佳參數重新訓練模型\n",
    "    best_svr = SVR(kernel='rbf', **best_params)\n",
    "    best_svr_model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('scaler_post',  StandardScaler(with_mean=False)),\n",
    "        ('regressor',    best_svr)\n",
    "    ])\n",
    "    best_svr_model.fit(X_train, y_train)\n",
    "\n",
    "    # 驗證集評估\n",
    "    y_val_pred = best_svr_model.predict(X_val)\n",
    "    mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "    r2_val = r2_score(y_val, y_val_pred)\n",
    "    \n",
    "    # 測試集評估\n",
    "    df_test_method = df_test_final[df_test_final['ship_method'] == method].copy()\n",
    "    if not df_test_method.empty:\n",
    "        X_test = df_test_method[feature_cols]\n",
    "        y_test = df_test_method[target_col]\n",
    "        y_test_pred = best_svr_model.predict(X_test)\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "        r2_test  = r2_score(y_test, y_test_pred)\n",
    "    else:\n",
    "        mse_test = r2_test = None\n",
    "\n",
    "# 儲存結果\n",
    "    results.append({\n",
    "        'ship_method': method,\n",
    "        'mse_val': mse_val,\n",
    "        'r2_val':  r2_val,\n",
    "        'mse_test': mse_test,\n",
    "        'r2_test':  r2_test,\n",
    "        'best_params': best_params\n",
    "    })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73044a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results with Optuna optimization:\n",
      "      ship_method   mse_val    r2_val  mse_test   r2_test  \\\n",
      "0  AMAZON_FREIGHT  0.209166  0.921933  0.770382  0.689501   \n",
      "\n",
      "                                         best_params  test_n  train_n  \n",
      "0  {'C': 150.14618361731786, 'epsilon': 0.0066413...      32      290  \n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "# Add test_n column: count of test samples for each ship_method\n",
    "test_n_list = []\n",
    "train_n_list = []\n",
    "for r in results:\n",
    "    method = r['ship_method']\n",
    "    n_test = df_test_final[df_test_final['ship_method'] == method].shape[0]\n",
    "    n_train = df_train_full[df_train_full['ship_method'] == method].shape[0]\n",
    "    test_n_list.append(n_test)\n",
    "    train_n_list.append(n_train)\n",
    "results_df['test_n'] = test_n_list\n",
    "results_df['train_n'] = train_n_list\n",
    "\n",
    "print(\"\\nResults with Optuna optimization:\")\n",
    "print(results_df.sort_values(by='mse_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8df4638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature  importance       std\n",
      "0  log_weight    2.927363  0.406883\n",
      "2    to_state    1.440990  0.309009\n",
      "1    log_Hdis    0.962254  0.246745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# 假設 svr_model 已訓練好\n",
    "best_svr_model.fit(X_train, y_train)\n",
    "result = permutation_importance(best_svr_model, X_val, y_val, n_repeats=10, random_state=42, scoring='neg_mean_squared_error')\n",
    "\n",
    "# 顯示特徵重要性\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': result.importances_mean,\n",
    "    'std': result.importances_std\n",
    "})\n",
    "print(feature_importance.sort_values(by='importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31bdfd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" import matplotlib.pyplot as plt\\n\\nplt.figure(figsize=(6,6))\\n# 畫理想線\\nmin_val = min(y_val.min(), y_test.min())\\nmax_val = max(y_val.max(), y_test.max())\\nplt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Ideal')\\n\\n# 畫驗證集\\nplt.scatter(y_val, y_val_pred, alpha=0.7, label='Validation Set')\\n# 畫測試集\\nplt.scatter(y_test, y_test_pred, alpha=0.7, color='orange', label='Test Set')\\n\\nplt.xlabel('Actual Value')\\nplt.ylabel('Predicted Value')\\nplt.title('Actual vs. Predicted - 'f'{method} Method')\\nplt.legend()\\nplt.show() \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "# 畫理想線\n",
    "min_val = min(y_val.min(), y_test.min())\n",
    "max_val = max(y_val.max(), y_test.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Ideal')\n",
    "\n",
    "# 畫驗證集\n",
    "plt.scatter(y_val, y_val_pred, alpha=0.7, label='Validation Set')\n",
    "# 畫測試集\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.7, color='orange', label='Test Set')\n",
    "\n",
    "plt.xlabel('Actual Value')\n",
    "plt.ylabel('Predicted Value')\n",
    "plt.title('Actual vs. Predicted - 'f'{method} Method')\n",
    "plt.legend()\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20fa7da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json, numpy as np\n",
    "from joblib import dump\n",
    "\n",
    "#寫一個專用轉換器\n",
    "def json_serial(obj):            # 讓 json.dump 能吃 numpy 型別\n",
    "    if isinstance(obj, (np.integer,)):\n",
    "        return int(obj)          # 轉成原生 int\n",
    "    if isinstance(obj, (np.floating,)):\n",
    "        return float(obj)        # 轉成原生 float\n",
    "    if isinstance(obj, (np.ndarray,)):\n",
    "        return obj.tolist()      # 把陣列攤平成 list\n",
    "    return str(obj)              # 其他自訂類別保底轉成字串\n",
    "\n",
    "# 寫 metadata.json，把重要資訊整理成 dict\n",
    "metadata = {\n",
    "\"ship_method\": method,\n",
    "\"target_col\": target_col,\n",
    "\"selected_features\": feature_cols,\n",
    "\"num_features\": [f for f in feature_cols if f in numeric_cols],\n",
    "\"cat_features\": [f for f in feature_cols if f not in numeric_cols],\n",
    "\"best_params\": best_params,\n",
    "# 轉成 {feature: importance}，比較容易讀\n",
    "\"feature_importance\": dict(\n",
    "    zip(feature_importance[\"feature\"], feature_importance[\"importance\"])\n",
    "),\n",
    "# 如果日後要比對資料量，可額外留下\n",
    "\"n_train\": len(X_train),\n",
    "\"n_val\": len(X_val),\n",
    "\"n_test\": len(df_test_method) if \"df_test_method\" in locals() else 0,\n",
    "\"timestamp\": datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "# 2) 決定輸出資料夾並確保存在\n",
    "output_dir = Path(\"model_artifacts\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 3) 寫出 json（default=_json_serial 會自動把 numpy 型別轉成原生 Python）\n",
    "with open(output_dir / f\"{method}_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False, default=json_serial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73c56d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92d13749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "\n",
    "model_path = output_dir / f\"{method}_model.pkl\"\n",
    "with open(model_path, \"wb\") as f:\n",
    "    cloudpickle.dump(best_svr_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882aeb74",
   "metadata": {},
   "source": [
    "#### 在存檔那台機器先記錄版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25dffc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip freeze > {method}_requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

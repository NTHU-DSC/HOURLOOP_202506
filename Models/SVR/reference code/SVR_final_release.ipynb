{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "875c9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import optuna\n",
    "from my_encoders import TargetEncoder, FrequencyEncoder\n",
    "from my_functions import build_feature_cols, build_preprocessor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import cloudpickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6fb0f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12844, 33) (1427, 33)\n"
     ]
    }
   ],
   "source": [
    "ship_method_name = [\n",
    "    'AMAZON_FREIGHT', 'AMAZON_LTL', 'AMAZON_UPS_PARCEL', 'ESTES',\n",
    "    'HOUR_LOOP_FEDEX_PARCEL', 'UBER_LTL', 'WWE_PARCEL'\n",
    "]\n",
    "\n",
    "# 如果所有檔案都在目前工作目錄\n",
    "df_train_full = pd.concat(\n",
    "    [pd.read_csv(f\"{m}_train.csv\") for m in ship_method_name],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_test_final = pd.concat(\n",
    "    [pd.read_csv(f\"{m}_test.csv\") for m in ship_method_name],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "print(df_train_full.shape, df_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ced485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {\n",
    "    'AMAZON_FREIGHT' : ['log_weight', 'log_Hdis','to_state'],\n",
    "    'AMAZON_LTL' : ['log_weight', 'log_Hdis', 'vendor_name','from_state','across_state'],\n",
    "    'AMAZON_UPS_PARCEL' : ['log_weight', 'log_Hdis', 'log_volume'],\n",
    "    'ESTES' : ['log_weight', 'to_state'],\n",
    "    'HOUR_LOOP_FEDEX_PARCEL' : ['log_weight', 'log_Mdis', 'vendor_name', 'to_state'],\n",
    "    'UBER_LTL': ['log_weight', 'log_Mdis', 'from_state'],\n",
    "    'WWE_PARCEL' : ['log_weight', 'log_Hdis']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "481eefb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = {\n",
    "    'AMAZON_FREIGHT' : {\"C\": 55.736076560251256,\"epsilon\": 0.11231822165041438,\"gamma\": 0.23417860093980628},\n",
    "    'AMAZON_LTL' : {\"C\": 81.58311403532339,\"epsilon\": 0.39059242077416534,\"gamma\": 0.16158971758347687},\n",
    "    'AMAZON_UPS_PARCEL' : {\"C\": 8.904533233040649,\"epsilon\": 0.1739978188492485,\"gamma\": 0.1547630356902939},\n",
    "    'ESTES' : {\"C\": 755.6857857093129,\"epsilon\": 0.0228933541579891,\"gamma\": 0.028654501103860433},\n",
    "    'HOUR_LOOP_FEDEX_PARCEL' : {\"C\": 17.86094781544563,\"epsilon\": 0.014085184521747276,\"gamma\": 0.03983996372116524},\n",
    "    'UBER_LTL': {\"C\": 256.9555810753195,\"epsilon\": 0.3931105382575026,\"gamma\": 0.016519129924529242},\n",
    "    'WWE_PARCEL' : {\"C\": 3.748705218525931,\"epsilon\": 0.0018305110274133042,\"gamma\": 0.040580180904780175}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b591d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'log_cost'\n",
    "\n",
    "def make_feature_config(cols_dict):\n",
    "    cfg = {}\n",
    "    for method, feats in cols_dict.items():\n",
    "        num_cols = [f for f in feats if f.startswith('log_')]\n",
    "        te_cols  = [f for f in feats if not f.startswith('log_')]\n",
    "        fe_cols  = []\n",
    "\n",
    "        cfg[method] = {\n",
    "            'numeric_cols'      : num_cols,\n",
    "            'target_encode_cols': te_cols,\n",
    "            'freq_encode_cols'  : fe_cols,\n",
    "            'feature_cols'      : build_feature_cols(num_cols, te_cols, fe_cols),\n",
    "            'preprocessor'      : build_preprocessor(num_cols, te_cols, fe_cols)\n",
    "        }\n",
    "    return cfg\n",
    "\n",
    "feature_config = make_feature_config(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1c199e",
   "metadata": {},
   "source": [
    "#### 建立模型並輸出指標結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ef1d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_baseline = []\n",
    "\n",
    "for method in df_train_full['ship_method'].unique():\n",
    "    df_method = df_train_full[df_train_full['ship_method'] == method].copy()\n",
    "    \n",
    "    cfg = feature_config[method]\n",
    "    feature_cols = cfg['feature_cols']\n",
    "    preprocessor = cfg['preprocessor']\n",
    "    numeric_cols = cfg['numeric_cols']\n",
    "    target_encode_cols = cfg['target_encode_cols']\n",
    "    freq_encode_cols = cfg['freq_encode_cols']\n",
    "\n",
    "    X = df_method[feature_cols]\n",
    "    y = df_method[target_col]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 使用預設參數\n",
    "    svr = SVR(kernel='rbf')\n",
    "    svr_model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('scaler_post', StandardScaler(with_mean=False)),\n",
    "        ('regressor', svr)\n",
    "    ])\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(svr_model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "    mse_cv = -scores.mean()\n",
    "\n",
    "    svr_model.fit(X_train, y_train)\n",
    "\n",
    "    y_val_pred = svr_model.predict(X_val)\n",
    "    mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "    r2_val = r2_score(y_val, y_val_pred)\n",
    "    \n",
    "    df_test_method = df_test_final[df_test_final['ship_method'] == method].copy()\n",
    "    if not df_test_method.empty:\n",
    "        X_test = df_test_method[feature_cols]\n",
    "        y_test = df_test_method[target_col]\n",
    "        y_test_pred = svr_model.predict(X_test)\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "    else:\n",
    "        mse_test = r2_test = None\n",
    "\n",
    "    results_baseline.append({\n",
    "        'ship_method': method,\n",
    "        'mse_cv': mse_cv,\n",
    "        'mse_val': mse_val,\n",
    "        'r2_val': r2_val,\n",
    "        'mse_test': mse_test,\n",
    "        'r2_test': r2_test,\n",
    "        'best_params': {'C': 1.0, 'epsilon': 0.1, 'gamma': 'scale'}\n",
    "    })\n",
    "\n",
    "baseline_results= pd.DataFrame(results_baseline)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f9c7622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results with Baseline:\n",
      "              ship_method    mse_cv   mse_val    r2_val  mse_test   r2_test  \\\n",
      "2       AMAZON_UPS_PARCEL  0.075654  0.083776  0.925854  0.101571  0.901698   \n",
      "1              AMAZON_LTL  0.190838  0.214385  0.843648  0.154047  0.606238   \n",
      "4  HOUR_LOOP_FEDEX_PARCEL  0.201951  0.167015  0.850018  0.175911  0.799376   \n",
      "6              WWE_PARCEL  0.129717  0.128389  0.866717  0.232287  0.715230   \n",
      "5                UBER_LTL  0.343826  0.237869  0.832960  0.284515  0.821755   \n",
      "3                   ESTES  0.217613  0.176954  0.904801  0.368477  0.748736   \n",
      "0          AMAZON_FREIGHT  0.210428  0.146166  0.945446  1.048730  0.577314   \n",
      "\n",
      "                                    best_params  \n",
      "2  {'C': 1.0, 'epsilon': 0.1, 'gamma': 'scale'}  \n",
      "1  {'C': 1.0, 'epsilon': 0.1, 'gamma': 'scale'}  \n",
      "4  {'C': 1.0, 'epsilon': 0.1, 'gamma': 'scale'}  \n",
      "6  {'C': 1.0, 'epsilon': 0.1, 'gamma': 'scale'}  \n",
      "5  {'C': 1.0, 'epsilon': 0.1, 'gamma': 'scale'}  \n",
      "3  {'C': 1.0, 'epsilon': 0.1, 'gamma': 'scale'}  \n",
      "0  {'C': 1.0, 'epsilon': 0.1, 'gamma': 'scale'}  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResults with Baseline:\")\n",
    "print(baseline_results.sort_values(by='mse_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52d4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_optuna = []\n",
    "\n",
    "for method in df_train_full['ship_method'].unique():\n",
    "    df_method = df_train_full[df_train_full['ship_method'] == method].copy()\n",
    "    \n",
    "    cfg = feature_config[method]\n",
    "    feature_cols = cfg['feature_cols']\n",
    "    preprocessor = cfg['preprocessor']\n",
    "    numeric_cols = cfg['numeric_cols']\n",
    "    target_encode_cols = cfg['target_encode_cols']\n",
    "    freq_encode_cols = cfg['freq_encode_cols']\n",
    "    best_params = vars[method]  # 直接使用 vars 中的參數\n",
    "\n",
    "    X = df_method[feature_cols]\n",
    "    y = df_method[target_col]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # ✨ Step 1: 編碼器 fit_transform（注意：TargetEncoder 需要 y）\n",
    "    X_train_proc = preprocessor.fit_transform(X_train, y_train)\n",
    "    X_val_proc   = preprocessor.transform(X_val)\n",
    "\n",
    "    # ✨ Step 2: 標準化（這部分仍包含在模型中）\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    X_train_scaled = scaler.fit_transform(X_train_proc)\n",
    "    X_val_scaled   = scaler.transform(X_val_proc)\n",
    "\n",
    "    # ✨ Step 3: 訓練 SVR 模型\n",
    "    svr = SVR(kernel='rbf', **best_params)\n",
    "    svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # ✨ Step 3: 組成純模型 pipeline（不包含 encoder）\n",
    "    best_svr_model = Pipeline([\n",
    "        ('scaler_post', scaler),\n",
    "        ('regressor', svr)\n",
    "    ])\n",
    "\n",
    "    # ✨ Step 4: cross_val_score（使用轉換後資料）\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(best_svr_model, X_train_proc, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "    mse_cv = -scores.mean()\n",
    "\n",
    "    # 儲存模型\n",
    "    output_dir = Path(\"model_artifacts_01\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model_path = output_dir / f\"{method}_model.pkl\"\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        cloudpickle.dump(best_svr_model, f)\n",
    "\n",
    "    # ✨ Step 6: 驗證集預測（需手動 transform）\n",
    "    y_val_pred = best_svr_model.predict(X_val_proc)\n",
    "    mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "    r2_val = r2_score(y_val, y_val_pred) \n",
    "\n",
    "    # ✨ Step 7: 測試集評估\n",
    "    df_test_method = df_test_final[df_test_final['ship_method'] == method].copy()\n",
    "    if not df_test_method.empty:\n",
    "        X_test = df_test_method[feature_cols]\n",
    "        y_test = df_test_method[target_col]\n",
    "        X_test_proc   = preprocessor.transform(X_test)\n",
    "        X_test_scaled = scaler.transform(X_test_proc)\n",
    "        y_test_pred   = best_svr_model.predict(X_test_scaled)\n",
    "\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "        r2_test  = r2_score(y_test, y_test_pred)\n",
    "    else:\n",
    "        mse_test = r2_test = None\n",
    "\n",
    "    # 儲存經過編碼的資料\n",
    "    encoded_df = pd.DataFrame(X_train_proc)\n",
    "    encoded_df[\"log_cost\"] = y_train.values  # 加上目標欄位（可選）\n",
    "    encoded_df.to_csv(f\"encoded_{method}.csv\", index=False)\n",
    "\n",
    "    results_optuna.append({\n",
    "        'ship_method': method,\n",
    "        'mse_cv': mse_cv,\n",
    "        'mse_val': mse_val,\n",
    "        'r2_val': r2_val,\n",
    "        'mse_test': mse_test,\n",
    "        'r2_test': r2_test,\n",
    "        'best_params': best_params\n",
    "    })\n",
    "\n",
    "\n",
    "optuna_results= pd.DataFrame(results_optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb745153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results with Optuna optimization:\n",
      "              ship_method    mse_cv   mse_val    r2_val  mse_test   r2_test  \\\n",
      "2       AMAZON_UPS_PARCEL  0.074693  0.081329  0.928019  0.097274  0.905857   \n",
      "1              AMAZON_LTL  0.161407  0.170339  0.875771  0.149549  0.617735   \n",
      "4  HOUR_LOOP_FEDEX_PARCEL  0.162398  0.145677  0.869180  0.160495  0.816957   \n",
      "6              WWE_PARCEL  0.123628  0.141278  0.853337  0.215929  0.735284   \n",
      "5                UBER_LTL  0.326313  0.243017  0.829345  0.256660  0.839205   \n",
      "3                   ESTES  0.202877  0.149603  0.919515  0.350116  0.761256   \n",
      "0          AMAZON_FREIGHT  0.138616  0.215691  0.919497  0.514058  0.792811   \n",
      "\n",
      "                                         best_params  \n",
      "2  {'C': 8.904533233040649, 'epsilon': 0.17399781...  \n",
      "1  {'C': 81.58311403532339, 'epsilon': 0.39059242...  \n",
      "4  {'C': 17.86094781544563, 'epsilon': 0.01408518...  \n",
      "6  {'C': 3.748705218525931, 'epsilon': 0.00183051...  \n",
      "5  {'C': 256.9555810753195, 'epsilon': 0.39311053...  \n",
      "3  {'C': 755.6857857093129, 'epsilon': 0.02289335...  \n",
      "0  {'C': 55.736076560251256, 'epsilon': 0.1123182...  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResults with Optuna optimization:\")\n",
    "print(optuna_results.sort_values(by='mse_test'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

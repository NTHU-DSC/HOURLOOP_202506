{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reference Notebook: Linear Regression (OLS, Ridge, Lasso)\n",
        "\n",
        "This notebook provides a clean, structured implementation of linear models for shipping cost prediction.\n"
      ],
      "metadata": {
        "id": "bNj7io6tPSPV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_PVU28TPPnE"
      },
      "outputs": [],
      "source": [
        "## 1. Imports and Setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob, os, itertools\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "def adjusted_r2(r2, n, p):\n",
        "    \"\"\"\n",
        "    Compute adjusted R squared.\n",
        "    r2: R^2 value\n",
        "    n: number of observations\n",
        "    p: number of predictors\n",
        "    \"\"\"\n",
        "    return 1 - (1 - r2) * (n - 1) / (n - p - 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. Load Data Files\n",
        "\n",
        "# Identify train/test CSVs in working directory\n",
        "train_files = sorted(glob.glob('*_train.csv'))\n",
        "test_files  = sorted(glob.glob('*_test.csv'))\n",
        "\n",
        "def get_test_file(train_fp):\n",
        "    ship = os.path.basename(train_fp).replace('_train.csv','')\n",
        "    return next((f for f in test_files if ship in f), None)"
      ],
      "metadata": {
        "id": "vcRFmL5MPYt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 3. Baseline OLS Model\n",
        "\n",
        "#Use only `log_weight` as a simple baseline.\n",
        "\n",
        "results = []\n",
        "for train_fp in train_files:\n",
        "    test_fp = get_test_file(train_fp)\n",
        "    if not test_fp: continue\n",
        "    ship = os.path.basename(train_fp).split('_')[0]\n",
        "    df_tr = pd.read_csv(train_fp)\n",
        "    df_te = pd.read_csv(test_fp)\n",
        "\n",
        "    X_tr = df_tr[['log_weight']]; y_tr = df_tr['log_cost']\n",
        "    X_te = df_te[['log_weight']]; y_te = df_te['log_cost']\n",
        "\n",
        "    scaler = StandardScaler().fit(X_tr)\n",
        "    X_tr_s, X_te_s = scaler.transform(X_tr), scaler.transform(X_te)\n",
        "\n",
        "    model = LinearRegression().fit(X_tr_s, y_tr)\n",
        "    y_pred = model.predict(X_te_s)\n",
        "    mse = mean_squared_error(y_te, y_pred)\n",
        "    r2  = r2_score(y_te, y_pred)\n",
        "\n",
        "    results.append({\n",
        "        'ship_method': ship,\n",
        "        'model': 'OLS',\n",
        "        'features': 'log_weight',\n",
        "        'val_MSE': round(mse,4),\n",
        "        'val_R2': round(r2,4)\n",
        "    })\n",
        "\n",
        "pd.DataFrame(results).sort_values(['ship_method'])"
      ],
      "metadata": {
        "id": "NjkibP7kPc3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. Ridge & Lasso with GridSearchCV\n",
        "\n",
        "# Define pipeline and grid\n",
        "pipe = Pipeline([('scaler', StandardScaler()), ('model', Ridge())])\n",
        "param_grid = {'model__alpha': [0.001,0.01,0.1,1,10,100]}\n",
        "\n",
        "gs_ridge = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Example on first ship_method\n",
        "df_example = pd.read_csv(train_files[0])\n",
        "X = df_example[['log_weight','log_volume']]; y = df_example['log_cost']\n",
        "gs_ridge.fit(X, y)\n",
        "print(\"Best Ridge alpha:\", gs_ridge.best_params_, \"| CV MSE:\", -gs_ridge.best_score_)\n",
        "\n",
        "# Repeat for Lasso\n",
        "gs_lasso = GridSearchCV(\n",
        "    Pipeline([('scaler', StandardScaler()), ('model', Lasso(max_iter=10000))]),\n",
        "    param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "gs_lasso.fit(X, y)\n",
        "print(\"Best Lasso alpha:\", gs_lasso.best_params_, \"| CV MSE:\", -gs_lasso.best_score_)\n"
      ],
      "metadata": {
        "id": "Fvle2mPDPh8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 5. Feature Combination Evaluation\n",
        "\n",
        "#Evaluate all subsets of continuous features:\n",
        "\n",
        "df = pd.read_csv(train_files[0])\n",
        "cont_feats = [c for c in df.columns if c.startswith('log_') and c!='log_cost']\n",
        "base = ['log_weight']\n",
        "combos = []\n",
        "for k in range(len(cont_feats)):\n",
        "    for combo in itertools.combinations(cont_feats[1:], k):\n",
        "        combos.append(base + list(combo))\n",
        "\n",
        "out = []\n",
        "for feats in combos:\n",
        "    X = df[feats]; y = df['log_cost']\n",
        "    scaler = StandardScaler().fit(X)\n",
        "    X_s = scaler.transform(X)\n",
        "    model = LinearRegression().fit(X_s, y)\n",
        "    pred = model.predict(X_s)\n",
        "    out.append({'features': feats,\n",
        "                'MSE': mean_squared_error(y, pred),\n",
        "                'R2': r2_score(y, pred)})\n",
        "pd.DataFrame(out).sort_values('MSE').head()\n"
      ],
      "metadata": {
        "id": "yRaRedhIPldy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 6. Incorporate Categorical Encoding\n",
        "\n",
        "# Define encoding columns\n",
        "ohe_cols  = ['across_state']\n",
        "freq_cols = ['from_state','to_state']\n",
        "te_col    = 'vendor_name'\n",
        "k_smooth  = 10\n",
        "\n",
        "# Build encoders\n",
        "def build_encoders(df):\n",
        "    ohe = OneHotEncoder(drop='first', sparse=False).fit(df[ohe_cols])\n",
        "    freq_maps = {col: df[col].value_counts().to_dict() for col in freq_cols}\n",
        "    global_mean = df['log_cost'].mean()\n",
        "    agg = df.groupby(te_col)['log_cost'].agg(['mean','count'])\n",
        "    te_map = {idx: (row['count']*row['mean']+k_smooth*global_mean)/(row['count']+k_smooth)\n",
        "              for idx,row in agg.iterrows()}\n",
        "    return ohe, freq_maps, te_map, global_mean\n",
        "\n",
        "# Apply encoding\n",
        "def encode_df(df, ohe, freq_maps, te_map, global_mean):\n",
        "    ohe_df = pd.DataFrame(ohe.transform(df[ohe_cols]),\n",
        "                          columns=ohe.get_feature_names_out(ohe_cols), index=df.index)\n",
        "    fe_df  = pd.DataFrame({f+ '_FE': df[f].map(freq_maps[f]) for f in freq_cols}, index=df.index)\n",
        "    te_df  = df[te_col].map(lambda x: te_map.get(x, global_mean)).rename('vendor_TE')\n",
        "    return pd.concat([df, ohe_df, fe_df, te_df], axis=1)\n"
      ],
      "metadata": {
        "id": "cVhqqwd-PoLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 7. Out-of-Time Validation\n",
        "\n",
        "#Use the `after` dataset for time-based stability check.\n",
        "\n",
        "df_after = pd.read_csv('Data_v8_after.csv')\n",
        "# Example: apply best model and encoders to df_after\n",
        "# ... (implementation as needed)\n"
      ],
      "metadata": {
        "id": "S2CBLrRSPq-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 8. Save Final Results\n",
        "\n",
        "final_df = pd.DataFrame(results)\n",
        "final_df.to_csv('linear_models_reference_results.csv', index=False)\n",
        "print(\"Results saved to linear_models_reference_results.csv\")"
      ],
      "metadata": {
        "id": "V7aFQNrgPta_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
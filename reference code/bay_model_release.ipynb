{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e67dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… æ¨¡å‹è¨“ç·´èˆ‡é¸æ“‡å·²å®Œæˆï¼Œè«‹æŸ¥çœ‹ï¼š\n",
      "ğŸ“ all_model_results_by_ship_method/\n",
      "ğŸ“„ model_result_summary_full.csv\n",
      "ğŸ“„ best_model_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import norm\n",
    "\n",
    "# === è³‡æ–™å¤¾è¨­å®š ===\n",
    "base_dir = \"Data v9\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "\n",
    "# === é¡åˆ¥èˆ‡é€£çºŒç‰¹å¾µçµ„åˆ ===\n",
    "cat_feature_sets = {\n",
    "    \"vendor_te\": [\"vendor_te\"],\n",
    "    \"across_state\": [\"across_state\"],\n",
    "    \"vendor_across\": [\"vendor_te\", \"across_state\"]\n",
    "}\n",
    "\n",
    "cont_base = [\"log_volume\", \"log_TVP\", \"log_TVP/log_weight\"]\n",
    "distance_variants = [[\"log_distance\"], [\"log_Hdis\"], [\"log_Mdis\"]]\n",
    "\n",
    "cont_combinations = []\n",
    "for r in range(1, len(cont_base) + 1):\n",
    "    for base_combo in itertools.combinations(cont_base, r):\n",
    "        for dist in distance_variants:\n",
    "            cont_combinations.append(list(base_combo) + dist)\n",
    "\n",
    "results = []\n",
    "os.makedirs(\"best_model_plots\", exist_ok=True)\n",
    "os.makedirs(\"best_model_coefficients\", exist_ok=True)\n",
    "os.makedirs(\"all_model_results_by_ship_method\", exist_ok=True)\n",
    "\n",
    "# === æ¯å€‹ ship_method å»ºæ¨¡ ===\n",
    "for file in os.listdir(train_dir):\n",
    "    if not file.endswith(\"_train.csv\"):\n",
    "        continue\n",
    "\n",
    "    method = file.replace(\"_train.csv\", \"\")\n",
    "    train_path = os.path.join(train_dir, file)\n",
    "    test_path = os.path.join(test_dir, f\"{method}_test.csv\")\n",
    "\n",
    "    if not os.path.exists(test_path):\n",
    "        continue\n",
    "\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "\n",
    "    if len(df_train) < 100 or len(df_test) == 0:\n",
    "        continue\n",
    "\n",
    "    df_train[\"across_state\"] = df_train[\"across_state\"].astype(int)\n",
    "    df_test[\"across_state\"] = df_test[\"across_state\"].astype(int)\n",
    "    vendor_mean = df_train.groupby(\"vendor_name\")[\"log_cost\"].mean()\n",
    "    global_mean = df_train[\"log_cost\"].mean()\n",
    "    df_train[\"vendor_te\"] = df_train[\"vendor_name\"].map(vendor_mean).fillna(global_mean)\n",
    "    df_test[\"vendor_te\"] = df_test[\"vendor_name\"].map(vendor_mean).fillna(global_mean)\n",
    "\n",
    "    ship_results = []\n",
    "\n",
    "    for cat_name, cat_feats in cat_feature_sets.items():\n",
    "        for cont_combo in cont_combinations:\n",
    "            all_feats = list(cat_feats) + list(cont_combo)\n",
    "\n",
    "            X_train = df_train[all_feats]\n",
    "            y_train = df_train[\"log_cost\"]\n",
    "            X_test = df_test[all_feats]\n",
    "            y_test = df_test[\"log_cost\"]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "            train_r2s, val_r2s = [], []\n",
    "            train_mses, val_mses = [], []\n",
    "\n",
    "            for train_idx, val_idx in kf.split(X_train_scaled):\n",
    "                X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "                y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "                model = BayesianRidge().fit(X_tr, y_tr)\n",
    "                y_tr_pred = model.predict(X_tr)\n",
    "                y_val_pred = model.predict(X_val)\n",
    "                train_r2s.append(r2_score(y_tr, y_tr_pred))\n",
    "                train_mses.append(mean_squared_error(y_tr, y_tr_pred))\n",
    "                val_r2s.append(r2_score(y_val, y_val_pred))\n",
    "                val_mses.append(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "            final_model = BayesianRidge().fit(X_train_scaled, y_train)\n",
    "            y_test_pred, y_test_std = final_model.predict(X_test_scaled, return_std=True)\n",
    "            test_r2 = r2_score(y_test, y_test_pred)\n",
    "            test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "            z = norm.ppf(0.975)  # 95% interval\n",
    "            pi_lower = y_test_pred - z * y_test_std\n",
    "            pi_upper = y_test_pred + z * y_test_std\n",
    "            pi_coverage = ((y_test >= pi_lower) & (y_test <= pi_upper)).mean()\n",
    "\n",
    "            ship_results.append({\n",
    "                \"ship_method\": method,\n",
    "                \"model\": cat_name,\n",
    "                \"cont_features\": \"+\".join(cont_combo),\n",
    "                \"Train_Adj_R2\": np.mean(train_r2s),\n",
    "                \"Train_MSE\": np.mean(train_mses),\n",
    "                \"Val_Adj_R2\": np.mean(val_r2s),\n",
    "                \"Val_MSE\": np.mean(val_mses),\n",
    "                \"Test_R2\": test_r2,\n",
    "                \"Test_MSE\": test_mse,\n",
    "                \"PI_coverage\": round(pi_coverage, 4),\n",
    "                \"N_train\": len(X_train),\n",
    "                \"N_test\": len(X_test)\n",
    "            })\n",
    "\n",
    "    ship_df = pd.DataFrame(ship_results)\n",
    "    ship_df.to_csv(f\"all_model_results_by_ship_method/{method}_model_results.csv\", index=False)\n",
    "    results.extend(ship_results)\n",
    "\n",
    "# åŒ¯å‡ºæ‰€æœ‰æ¨¡å‹çµæœ\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df.to_csv(\"bay_model_result_summary_full.csv\", index=False)\n",
    "\n",
    "# è‡ªå‹•é¸æœ€ä½³æ¨¡å‹\n",
    "best_models = result_df[result_df[\"PI_coverage\"] >= 0.95].sort_values(\"Test_MSE\").groupby(\"ship_method\").first().reset_index()\n",
    "best_models.to_csv(\"bay_best_model_summary.csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ… æ¨¡å‹è¨“ç·´èˆ‡é¸æ“‡å·²å®Œæˆï¼Œè«‹æŸ¥çœ‹ï¼š\")\n",
    "print(\"ğŸ“ all_model_results_by_ship_method/\")\n",
    "print(\"ğŸ“„ model_result_summary_full.csv\")\n",
    "print(\"ğŸ“„ best_model_summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
